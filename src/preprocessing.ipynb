{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fix directories, define path variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure notebook is ran from src\n",
    "cwd = os.getcwd()\n",
    "if not cwd.split(os.sep)[-1] == 'src':\n",
    "    try:\n",
    "        os.chdir('src')\n",
    "    except FileNotFoundError:\n",
    "        print('Error: please run from src dir or project root')\n",
    "        sys.exit(1)\n",
    "\n",
    "# define paths\n",
    "path = lambda x: os.path.join(*x.split('/')) + os.sep\n",
    "data_path = path('../data')\n",
    "csv_path = path('../data/csv')\n",
    "shp_path = path('../data/shapefiles')\n",
    "plot_path = path('../plots')\n",
    "for path in [data_path, csv_path, shp_path, plot_path]:\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Read data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function that handles everything**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\" Check if the file exists, if not download it. \"\"\"\n",
    "\n",
    "    assert name in ['trees', 'traffic', 'streets'], 'Invalid dataset name'\n",
    "    api = 'https://data.cityofnewyork.us/api/'\n",
    "    lookup = {\n",
    "        'trees': {\n",
    "            'path': csv_path + '2015_Street_Tree_Census_-_Tree_Data.csv',\n",
    "            'link': f'{api}views/uvpi-gqnh/rows.csv?accessType=DOWNLOAD',\n",
    "        },\n",
    "        'traffic': {\n",
    "            'path': csv_path + 'Automated_Traffic_Volume_Counts.csv',\n",
    "            'link': f'{api}views/7ym2-wayt/rows.csv?accessType=DOWNLOAD',\n",
    "        },\n",
    "        'streets': {\n",
    "            'path': shp_path + 'NYC Street Centerline (CSCL)',  # this is a dir!\n",
    "            'link': f'{api}geospatial/exjm-f27b?method=export&format=Shapefile',\n",
    "        },\n",
    "    }\n",
    "\n",
    "    if not os.path.exists(lookup[name]['path']):\n",
    "        print(f'Could not find {name} data, downloading...')\n",
    "        r = requests.get(lookup[name]['link'])\n",
    "        if r.status_code != 200:\n",
    "            print(f'Error: {r.status_code}')\n",
    "            sys.exit(1)\n",
    "        if name in ['trees', 'traffic']:\n",
    "            with open(lookup[name]['path'], 'w') as f:\n",
    "                f.write(r.text)\n",
    "        elif name == 'streets':\n",
    "            if not os.path.exists(lookup[name]['path']):\n",
    "                os.mkdir(lookup[name]['path'])\n",
    "            with open(lookup[name]['path'] + '/geo_export.zip', 'wb') as f:\n",
    "                f.write(r.content)\n",
    "            os.system(f'unzip \"{lookup[name][\"path\"]}/geo_export.zip\" -d \"{lookup[name][\"path\"]}\"')\n",
    "            os.system(f'rm \"{lookup[name][\"path\"]}/geo_export.zip\"')\n",
    "        print(f'Download complete. Data saved to {lookup[name][\"path\"]}.')\n",
    "    else:\n",
    "        print(f'Found {name} data, loading from disk...')\n",
    "\n",
    "    if name == 'trees':\n",
    "        df = pd.read_csv(lookup[name]['path'])\n",
    "        gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df['longitude'], df['latitude']), crs='epsg:4326')\n",
    "    elif name == 'traffic':\n",
    "        df = pd.read_csv(lookup[name]['path'], index_col='RequestID').rename(columns={'WktGeom': 'geometry'})\n",
    "        # only keep data of 2017\n",
    "        df = df[df['Yr'] == 2017]\n",
    "        # create a new column with the average traffic volume for each measurement point\n",
    "        df['Avg_Vol'] = df.groupby(['geometry', 'Direction'])['Vol'].transform('mean')\n",
    "        # drop unnecessary columns and rows\n",
    "        df = df.drop(['Yr', 'M', 'D', 'HH', 'MM','Vol'], axis=1)\n",
    "        df = df.drop_duplicates(subset=['geometry', 'Direction'])\n",
    "        # convert geometry column to shapely geometry\n",
    "        df.geometry = df.geometry.apply(wkt.loads)\n",
    "        gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "        # convert geometry from epsg 2263 (NAD83 / New York Long Island (ftUS)) to epsg 4326 (WGS 84)\n",
    "        gdf.crs = 2263\n",
    "        gdf = gdf.to_crs(epsg=4326)\n",
    "    elif name == 'streets':\n",
    "        # every download gets a different hash, so we need to find it\n",
    "        my_hash = os.listdir(lookup[name]['path'])[0].split('_')[-1].split('.')[0]\n",
    "        gdf = gpd.read_file(lookup[name]['path'] + f'/geo_export_{my_hash}.shp').to_crs(epsg=4326)\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Call function to get all gdfs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREES = load_data('trees')\n",
    "TRAFFIC = load_data('traffic')\n",
    "STREETS = load_data('streets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAFFIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Streets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STREETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Visualize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we just plot the measurement locations on street network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "STREETS.plot(ax=ax, color='grey', alpha=0.5, zorder=1)\n",
    "TRAFFIC.plot(\n",
    "    ax = ax,\n",
    "    column = 'Avg_Vol',\n",
    "    legend = True,\n",
    "    legend_kwds = dict(\n",
    "        label = 'Average Traffic Volume',\n",
    "        orientation = 'horizontal',\n",
    "        shrink = 0.8\n",
    "    ),\n",
    "    markersize = 5,\n",
    "    cmap = 'viridis_r',\n",
    "    zorder = 2\n",
    ")\n",
    "ax.set_axis_off()\n",
    "ax.set_title('Average Traffic Volume in NYC in 2017');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manhattan**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We restrict the scope of the analysis to Manhattan, because its traffic datapoints are relatively dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STREETS_ = STREETS[STREETS['borocode'] == '1']\n",
    "TRAFFIC_ = TRAFFIC[TRAFFIC['Boro'] == 'Manhattan']\n",
    "TREES_ = TREES[TREES['borough'] == 'Manhattan']\n",
    "\n",
    "for name, df, df_ in zip(['streets', 'traffic', 'trees'], [STREETS, TRAFFIC, TREES], [STREETS_, TRAFFIC_, TREES_]):\n",
    "    print(f'{name}: {df.shape[0]} -> {df_.shape[0]} ({df_.shape[0]/df.shape[0]:.2%})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 10))\n",
    "STREETS_.plot(ax=ax, color='grey', alpha=0.5, zorder=1)\n",
    "TRAFFIC_.plot(\n",
    "    ax = ax,\n",
    "    column = 'Avg_Vol',\n",
    "    legend = True,\n",
    "    legend_kwds = dict(\n",
    "        label = 'Average Traffic Volume',\n",
    "        orientation = 'horizontal',\n",
    "        shrink = 0.5,\n",
    "    ),\n",
    "    markersize = 5,\n",
    "    cmap = 'viridis_r',\n",
    "    zorder = 2\n",
    ")\n",
    "ax.set_axis_off()\n",
    "ax.set_title('Manhattan Traffic Volume in 2017');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to add the tree data to the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 10))\n",
    "STREETS_.plot(ax=ax, color='grey', alpha=0.5, zorder=1)\n",
    "TREES_.plot(\n",
    "    ax = ax,\n",
    "    markersize = 0.05,\n",
    "    color = 'green',\n",
    "    alpha = 0.1,\n",
    "    zorder = 2\n",
    ")\n",
    "TRAFFIC_.plot(\n",
    "    ax = ax,\n",
    "    column = 'Avg_Vol',\n",
    "    legend = True,\n",
    "    legend_kwds = dict(\n",
    "        label = 'Average Traffic Volume',\n",
    "        orientation = 'horizontal',\n",
    "        shrink = 0.5,\n",
    "        pad = 0,\n",
    "    ),\n",
    "    markersize = 5,\n",
    "    cmap = 'Reds',\n",
    "    zorder = 3\n",
    ")\n",
    "ax.set_axis_off()\n",
    "ax.set_title('Manhattan Traffic Volume in 2017\\nwith Street Trees')\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_path + 'traffic_trees_manhattan.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STREETS_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all streets left of -74.035 (Statue of Liberty and Ellis Island)\n",
    "size_before = STREETS_.shape[0]\n",
    "STREETS_ = STREETS_[STREETS_['geometry'].apply(lambda x: x.centroid.x > -74.035)]\n",
    "print(f'Removed {size_before - STREETS_.shape[0]} streets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Finally, we save the Manhattan gdfs to shapefiles for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gdf, name in zip([STREETS_, TRAFFIC_, TREES_], ['streets', 'traffic', 'trees']):\n",
    "    target_path = shp_path + name + '/'\n",
    "    if not os.path.exists(target_path):\n",
    "        os.mkdir(target_path)\n",
    "    # some column names will be truncated, but it's no big deal\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        gdf.to_file(target_path + f'M_{name}.shp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64750f2cf9258ce55ff4fa4c381516413ca0f47d1da9e17919bacb4d3e3ff9fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
