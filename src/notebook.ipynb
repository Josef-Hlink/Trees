{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix directories, define default variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure notebook is ran from src\n",
    "cwd = os.getcwd()\n",
    "if not cwd.split('/')[-1] == 'src':\n",
    "    try:\n",
    "        os.chdir('src')\n",
    "    except FileNotFoundError:\n",
    "        print('Error: please run from src dir or project root')\n",
    "        sys.exit(1)\n",
    "\n",
    "# define paths\n",
    "data_path = '../data/'\n",
    "csv_path = data_path + 'csv/'\n",
    "shp_path = data_path + 'shp/'\n",
    "plot_path = '../plots/'\n",
    "if not os.path.exists(plot_path):\n",
    "    os.mkdir(plot_path)\n",
    "\n",
    "# projection in which trees data is stored: \"Amersfoort / RD New\"\n",
    "proj = 28992"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trees data (converted to csv), tif file obtained from [Nationaal Georegister](https://www.nationaalgeoregister.nl/geonetwork/srv/dut/catalog.search#/metadata/89611780-75d6-4163-935f-9bc0a738f7ca)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path+'bomenkaart.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapefile, obtained from [EarthWorks](https://earthworks.stanford.edu/catalog/stanford-gp502yc4422)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_base = gpd.read_file(shp_path+'ADM0/NLD_adm0.shp').to_crs(epsg=proj)\n",
    "nl_base.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the data on a high level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "nl_base.plot(ax=ax, color='white', edgecolor='black')\n",
    "\n",
    "df_sample = df.sample(100_000)\n",
    "points = ax.scatter(\n",
    "    'x',\n",
    "    'y',\n",
    "    c = 'z',\n",
    "    data = df_sample,\n",
    "    s = 0.1,\n",
    "    cmap = 'viridis'\n",
    ")\n",
    "ax.set_axis_off()\n",
    "\n",
    "cbar = fig.colorbar(points, ax=ax, location='bottom', shrink=0.5, pad=0.05)\n",
    "cbar.set_label('number of trees per $100 \\: m^2$')\n",
    "fig.suptitle('Tree density in the Netherlands')\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_path+'trees.png', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "df['z'].hist(ax=ax, bins=100)\n",
    "ax.set_title('Distribution of tree density')\n",
    "ax.set_xlabel('number of trees per $100 \\: m^2$')\n",
    "ax.set_ylabel('number of observations')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foursquare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up Foursquare API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define credentials, which will be used as global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../credentials.json', 'r') as creds_file:\n",
    "    credentials = json.load(creds_file)\n",
    "\n",
    "fsq_creds = credentials['foursquare']\n",
    "client_id, client_secret = fsq_creds['client_id'], fsq_creds['client_secret']\n",
    "\n",
    "url = 'https://api.foursquare.com/v3/places/search'\n",
    "\n",
    "headers = dict(\n",
    "    accept = 'application/json',\n",
    "    authorization = fsq_creds['authorization']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to extract useful data from a Foursquare API response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_keys(d: dict, keys: list[str]) -> str:\n",
    "    \"\"\"   Recurses through a list of keys to access a path in a dictionary, robust against KeyError.   \"\"\"\n",
    "    data = d\n",
    "    try:\n",
    "        for key in keys:\n",
    "            data = data[key]\n",
    "    except KeyError:\n",
    "        return '-'\n",
    "    return data\n",
    "\n",
    "def venue_scraper(response: dict) -> pd.DataFrame:\n",
    "    \"\"\"   Extracts relevant venue data from a Foursquare API response.   \"\"\"    \n",
    "    df = pd.DataFrame(columns=['name', 'latitude', 'longitude', 'distance', 'address', 'genre'])\n",
    "    \n",
    "    for i, result in enumerate(response['results']):\n",
    "        name = result['name']\n",
    "        latitude = try_keys(result, ['geocodes', 'main', 'latitude'])\n",
    "        longitude = try_keys(result, ['geocodes', 'main', 'longitude'])\n",
    "        distance = try_keys(result, ['distance'])\n",
    "        address = try_keys(result, ['location', 'address'])\n",
    "        genre = [try_keys(category, ['name']) for category in result['categories']]\n",
    "\n",
    "        df.loc[i] = [name, latitude, longitude, distance, address, genre]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Foursquare API as POC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POC: get some venues that are nearby Snellius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    url,\n",
    "    headers = headers,\n",
    "    params = dict(\n",
    "        client_id = client_id,\n",
    "        client_secret = client_secret,\n",
    "        ll = '52.1665,4.4870',          # Snellius\n",
    "        radius = 3000,                  # should be enough to get 50 results\n",
    "        limit = 50                      # maximum limit allowed by fsq\n",
    "    )\n",
    ").json()\n",
    "\n",
    "fsq_df = venue_scraper(response)\n",
    "fsq_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POC: get \"all\" venues in the Netherlands (very spaced out as to not strain the API)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_venues(granularity: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"   Searches for all venues given a degree of granularity.   \"\"\"\n",
    "\n",
    "    # define bounding box for the Netherlands\n",
    "    bbox = [3.314971144228537, 50.80372101501058, 7.092053256873896, 53.51040334737801]\n",
    "\n",
    "    # define grid of evenly spaced points within bbox\n",
    "    xl = np.linspace(bbox[0], bbox[2], granularity)\n",
    "    yl = np.linspace(bbox[1], bbox[3], granularity)\n",
    "    xv, yv = np.meshgrid(xl, yl)\n",
    "    points = np.array([xv.flatten(), yv.flatten()]).T\n",
    "\n",
    "    # narrow down list of points that are within Dutch borders\n",
    "    points_gdf = gpd.GeoDataFrame(\n",
    "        points,\n",
    "        geometry = gpd.points_from_xy(points[:, 0], points[:, 1]),\n",
    "        crs = 'EPSG:4326'\n",
    "    ).to_crs(epsg=proj)\n",
    "\n",
    "    points_gdf = points_gdf[\n",
    "        points_gdf.within(nl_base.unary_union)\n",
    "    ].rename(\n",
    "        columns={0: 'lat', 1: 'lon'}\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # intialize empty dataframe\n",
    "    fsq_df = pd.DataFrame(columns=['name', 'latitude', 'longitude', 'distance', 'address', 'genre'])\n",
    "\n",
    "    # loop over cells in grid and add venues to dataframe\n",
    "    for i, (lat, lon, _) in points_gdf.iterrows():\n",
    "        print(f'{i+1}/{points_gdf.shape[0]}', end='\\r')\n",
    "\n",
    "        response = requests.get(\n",
    "            url,\n",
    "            headers = headers,\n",
    "            params = dict(\n",
    "                client_id = client_id,\n",
    "                client_secret = client_secret,\n",
    "                ll = f'{lon},{lat}',\n",
    "                radius = 3000,\n",
    "                limit = 50\n",
    "            )\n",
    "        ).json()\n",
    "        temp_df = venue_scraper(response)\n",
    "        fsq_df = pd.concat([fsq_df, temp_df], axis=0, ignore_index=True)\n",
    "\n",
    "    print()\n",
    "    return fsq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditionally load or create the Foursquare dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(csv_path+'fsq_venues.csv'):\n",
    "    fsq_df = pd.read_csv(csv_path+'fsq_venues.csv')\n",
    "else:\n",
    "    fsq_df = get_venues(granularity=5)\n",
    "    fsq_df.to_csv(csv_path+'fsq_venues.csv', index=False)\n",
    "\n",
    "# fsq_df = get_venues(granularity=10)\n",
    "# fsq_df.to_csv(csv_path+'fsq_venues.csv', index=False)\n",
    "\n",
    "fsq_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to geodataframe\n",
    "fsq_gdf = gpd.GeoDataFrame(\n",
    "    fsq_df,\n",
    "    geometry = gpd.points_from_xy(fsq_df['longitude'], fsq_df['latitude']),\n",
    "    crs = 'EPSG:4326'\n",
    ").to_crs(epsg=proj)\n",
    "\n",
    "# very basic plot\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "nl_base.plot(ax=ax, color='white', edgecolor='black')\n",
    "fsq_gdf.plot(ax=ax, markersize=0.5, color='red')\n",
    "ax.set_axis_off()\n",
    "ax.set_title('Foursquare venues in the Netherlands')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in shapefiles from \"shapefiles_rw\"\n",
    "gdf_rw = gpd.read_file(shp_path+'restwarmte/restwarmte.shp').to_crs(epsg=proj)\n",
    "gdf_rw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select outliers in 2013\n",
    "big_players = gdf_rw[gdf_rw['KGCO2_2013'] > 5e8].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "nl_base.plot(ax=ax, color='white', edgecolor='black')\n",
    "\n",
    "df_sample = df.sample(10000)\n",
    "points = ax.scatter(\n",
    "    'x',\n",
    "    'y',\n",
    "    c = 'z',\n",
    "    data = df_sample,\n",
    "    s = 0.1,\n",
    "    cmap = 'viridis'\n",
    ")\n",
    "\n",
    "big_players.plot(\n",
    "    ax = ax,\n",
    "    column = 'KGCO2_2013',\n",
    "    s = 100,\n",
    "    cmap = 'Reds'\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_path+'rw_heatmap.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_players.hist(column='KGCO2_2013', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_co2 = gpd.read_file(data_path+'co2/gemeentes.geojson').to_crs(epsg=proj)\n",
    "\n",
    "gdf_co2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_co2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert co2 to log\n",
    "gdf_co2['co2_log'] = np.log(gdf_co2['co2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "gdf_co2.plot(\n",
    "    column = 'co2_log',\n",
    "    cmap = 'Reds',\n",
    "    linewidth = 1,\n",
    "    edgecolor = 'black',\n",
    "    legend = True,\n",
    "    ax = ax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density = pd.read_csv(csv_path+'bevolkingsdichtheid.csv', sep=';')\n",
    "density = density.rename({'Inwoners per km² land': 'density', 'Gemeente': 'rname'}, axis=1)\n",
    "print(density.shape)\n",
    "density.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge density data with gdf\n",
    "gdf_m = gdf_co2.merge(density, on='rname', how='right')\n",
    "print(gdf_co2.shape)\n",
    "print(gdf_m.shape)\n",
    "gdf_m.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print difference gdf_co2 - gdf_m\n",
    "gdf_co2[~gdf_co2['rname'].isin(gdf_m['rname'])]['rname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print difference density - gdf_co2\n",
    "density[~density['Gemeente'].isin(gdf_co2['rname'])]['Gemeente'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a mess, probably will need different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast density to float\n",
    "gdf_m['density'] = gdf_m['density'].apply(lambda x: x.replace(' ', '')).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "gdf_co2.plot(\n",
    "    color = 'Blue',\n",
    "    linewidth = 1,\n",
    "    edgecolor = 'black',\n",
    "    ax = ax\n",
    ")\n",
    "\n",
    "gdf_m.plot(\n",
    "    column = 'density',\n",
    "    cmap = 'Reds',\n",
    "    linewidth = 1,\n",
    "    edgecolor = 'black',\n",
    "    legend = True,\n",
    "    ax = ax\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blue values are \"missing\" from our population density dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64750f2cf9258ce55ff4fa4c381516413ca0f47d1da9e17919bacb4d3e3ff9fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
